{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83291c1",
   "metadata": {
    "id": "a83291c1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import datetime\n",
    "import os\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from matplotlib.mlab import psd\n",
    "\n",
    "from scipy import integrate, optimize\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def every_nth(nums, nth):\n",
    "    # Use list slicing to return elements starting from the (nth-1) index, with a step of 'nth'.\n",
    "    return nums[nth - 1::nth]\n",
    "\n",
    "def calibrate_frequency_domain(freq_domain, freqs, calibration_factors, phase_data):\n",
    "    calibrated_freq_domain = np.zeros_like(freq_domain, dtype=complex)\n",
    "    for i, freq in enumerate(freqs):\n",
    "        if freq >= 0:  # Only process positive frequencies\n",
    "            calibration_factor = calibration_factors[i]\n",
    "            phase = phase_data[i]\n",
    "\n",
    "            # Apply calibration factor and phase correction\n",
    "            # the 2* is for one sided freq>0\n",
    "            calibrated_freq_domain[i] = 2 * freq_domain[i] / calibration_factor * np.exp(1j * phase)\n",
    "    return calibrated_freq_domain\n",
    "\n",
    "def compute_noise_spectral_density(time_series, sampling_rate):\n",
    "    # Calculate the length of the time series\n",
    "    n = len(time_series)\n",
    "\n",
    "    # Compute the Fast Fourier Transform (FFT)\n",
    "    fft_result = np.fft.fft(time_series)\n",
    "\n",
    "    # Calculate the one-sided power spectral density\n",
    "    psd = (1 / (sampling_rate * n)) * np.abs(fft_result[:n//2])**2\n",
    "\n",
    "    # Calculate the corresponding frequencies\n",
    "    freqs = np.fft.fftfreq(n, 1/sampling_rate)[:n//2]\n",
    "\n",
    "    return freqs, np.sqrt(psd)\n",
    "\n",
    "# seconds from (1970/01/01 00:00:00.0) to gps epoch (1980/01/06 00:00:19.0), ignoring leap-seconds\n",
    "gpsEpoch = 315964819.\n",
    "# Constants\n",
    "SampleRate = 2597\n",
    "rho = 6.04e7 # in nT^2 dark matter density in magnetic field units\n",
    "R = 0.0212751 # in Hz^-1 Radius of earth divided by c\n",
    "fd = 1 / 86164 # in Hz, rotation frequency of the Earth (1/day)\n",
    "dT = 1/SampleRate # sampling period (in s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f1526",
   "metadata": {
    "id": "f99f1526"
   },
   "outputs": [],
   "source": [
    "pathLemmy = '/Users/gc2138/Desktop/SNIPE/LemmySimul'\n",
    "pathPhil = '/Users/gc2138/Desktop/SNIPE/PhilSimul'\n",
    "\n",
    "os.chdir(pathLemmy)\n",
    "folder_files = os.listdir(pathLemmy)\n",
    "\n",
    "#Load Time Series from File\n",
    "# put data into a list\n",
    "BdataN = [];\n",
    "concatTimeN = [];\n",
    "BdataE = [];\n",
    "concatTimeE = [];\n",
    "\n",
    "downsampleFactor = 1; # originally had because Katie's computer couldn't handle large amounts of data\n",
    "scaleFactor = 1; # to account for amplification after LEMI\n",
    "\n",
    "for file in folder_files:\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        dataN = f['data'][()] * scaleFactor\n",
    "        timestamps = f['timestamps'][()]\n",
    "        concatTimeN.extend(timestamps)\n",
    "\n",
    "        #Downsampling data\n",
    "        for n in range(len(dataN[0,:])):\n",
    "              nums = every_nth(dataN[:,n], downsampleFactor)\n",
    "              BdataN.extend(nums)\n",
    "\n",
    "os.chdir(pathPhil)\n",
    "folder_files = os.listdir(pathPhil)\n",
    "\n",
    "for file in folder_files:\n",
    "    with h5py.File(file, 'r') as f:\n",
    "        dataE = f['data'][()] * scaleFactor\n",
    "        timestamps = f['timestamps'][()]\n",
    "        concatTimeE.extend(timestamps)\n",
    "\n",
    "        #Downsampling data\n",
    "        for n in range(len(dataE[0,:])):\n",
    "              nums = every_nth(dataE[:,n], downsampleFactor)\n",
    "              BdataE.extend(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbe1672",
   "metadata": {
    "id": "bcbe1672"
   },
   "outputs": [],
   "source": [
    "# load lemmy and phil data, get coords for our station, calibrate data after FFT\n",
    "\n",
    "#convert coordinates into radians\n",
    "[latL,longL] = (39 + 6.024/60)*np.pi/180, (120 + 55.386/60)*np.pi/180\n",
    "[latP, longP] = (39 + 6.101/60)*np.pi/180, (120 + 55.426/60)*np.pi/180\n",
    "\n",
    "#convert to spherical coordinates for theta\n",
    "latL = np.pi/2 - latL;\n",
    "LatP = np.pi/2 - latP;\n",
    "\n",
    "lat1 = latL\n",
    "long1 = longP\n",
    "\n",
    "#Range of frequencies analyzed\n",
    "lowFreq,highFreq = [0.1,5.0];\n",
    "\n",
    "N = len(BdataN)\n",
    "fp = int(lowFreq*N*dT) # this picks out the data point in our list corresponding to lowFreq = Ntot LowFreq/(frequency span)\n",
    "fq = int(highFreq*N*dT)+1;\n",
    "\n",
    "\n",
    "# Construct data vector\n",
    "fdhat = int(np.round(fd * N * dT)) # fdhat index. fdhat is closest discrete frequency interval to fd (fd = 1/day)\n",
    "FFT1 = -dT*np.fft.fft(BdataN)\n",
    "FFT2 = dT*np.fft.fft(BdataE)\n",
    "\n",
    "os.chdir('/Users/gc2138/Desktop/SNIPE')\n",
    "calibrationL = 'LEMMYCalibration691text.csv'\n",
    "calibrationP = 'PHILCalibration748text.csv'\n",
    "\n",
    "freqsN, noise_spectral_densityN = compute_noise_spectral_density(BdataN, SampleRate)\n",
    "freqsE, noise_spectral_densityE = compute_noise_spectral_density(BdataE, SampleRate)\n",
    "\n",
    "calibration_dataL = np.loadtxt(calibrationL, delimiter = \",\")\n",
    "calibration_dataP = np.loadtxt(calibrationP, delimiter = \",\")\n",
    "\n",
    "frequency_calibrationL = calibration_dataL[:, 0]  # Frequency values in Hz\n",
    "voltage_calibrationL = 10**-3 * calibration_dataL[:, 1]    # Volts per nano-Tesla (original calibration data is in mV/nT)\n",
    "phase_calibrationL = calibration_dataL[:,2]\n",
    "\n",
    "frequency_calibrationP = calibration_dataP[:, 0]  # Frequency values in Hz\n",
    "voltage_calibrationP = 10**-3 * calibration_dataP[:, 1]    # Volts per nano-Tesla (original calibration data is in mV/nT)\n",
    "phase_calibrationP = calibration_dataP[:,2]\n",
    "\n",
    "# calculates the calibration factor at every frequency in FFT of our data\n",
    "voltage_calibration_interpolatedN = np.interp(np.abs(freqsN), frequency_calibrationL, voltage_calibrationL)\n",
    "phase_correction_interpolatedN = np.interp(np.abs(freqsN), frequency_calibrationL, phase_calibrationL)\n",
    "voltage_calibration_interpolatedE = np.interp(np.abs(freqsE), frequency_calibrationP, voltage_calibrationP)\n",
    "phase_correction_interpolatedE = np.interp(np.abs(freqsE), frequency_calibrationP, phase_calibrationP)\n",
    "\n",
    "calFFT1 = calibrate_frequency_domain(FFT1, freqsN, voltage_calibration_interpolatedN, phase_correction_interpolatedN)\n",
    "calFFT2 = calibrate_frequency_domain(FFT2, freqsE, voltage_calibration_interpolatedE, phase_correction_interpolatedE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c02591f",
   "metadata": {
    "id": "3c02591f"
   },
   "outputs": [],
   "source": [
    "# Vector of complete FT data at Compton frequency + sidebands\n",
    "X = np.stack([calFFT1[fp - fdhat : fq - fdhat], calFFT2[fp - fdhat : fq - fdhat],\n",
    "              calFFT1[fp : fq], calFFT2[fp : fq],\n",
    "              calFFT1[fp + fdhat : fq + fdhat], calFFT2[fp + fdhat : fq + fdhat]])\n",
    "\n",
    "# Compute expectation value\n",
    "# Discrete sampling correction for sidebands\n",
    "Q = lambda f: (1 - np.exp(-2 * np.pi * 1j * f * N * dT)) / (1 - np.exp(-2 * np.pi * 1j * f * dT))\n",
    "\n",
    "# basis vectors for dark matter signal\n",
    "mu0 = -N * dT * np.sqrt(rho / 2) * np.array([\n",
    "    0, 0, 0, np.sin(lat1), 0, 0])\n",
    "muplus = -dT * np.sqrt(rho) / 2 * np.array([\n",
    "    1j * np.exp(-1j * long1) * Q(fd - fdhat / N / dT), np.cos(lat1) * np.exp(-1j * long1) * Q(fd - fdhat / N / dT),\n",
    "    1j * np.exp(-1j * long1) * Q(fd), np.cos(lat1) * np.exp(-1j * long1) * Q(fd),\n",
    "    1j * np.exp(-1j * long1) * Q(fd + fdhat / N / dT), np.cos(lat1) * np.exp(-1j * long1) * Q(fd + fdhat / N / dT)])\n",
    "muminus = -dT * np.sqrt(rho) / 2 * np.array([\n",
    "    -1j * np.exp(1j * long1) * Q(fd - fdhat / N / dT), np.cos(lat1) * np.exp(1j * long1) * Q(fd - fdhat / N / dT),\n",
    "    -1j * np.exp(1j * long1) * Q(fd), np.cos(lat1) * np.exp(1j * long1) * Q(fd),\n",
    "    -1j * np.exp(1j * long1) * Q(fd + fdhat / N / dT), np.cos(lat1) * np.exp(1j * long1) * Q(fd + fdhat / N / dT)])\n",
    "# Note that mu, nu, and S are all missing a factor of frequency, so that they can be frequency independent.  This factor will be added back when computing the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acfbb1e",
   "metadata": {
    "id": "1acfbb1e"
   },
   "outputs": [],
   "source": [
    "# Compute covariance matrix\n",
    "Sigma = np.sum(X[2:4, None] * np.conj(X[2:4]), axis = -1) / (fq - fp)\n",
    "\n",
    "inva = np.linalg.inv(np.linalg.cholesky(Sigma))\n",
    "\n",
    "invA = np.block([[inva, np.zeros((2, 2)), np.zeros((2, 2))],\n",
    "                 [np.zeros((2, 2)), inva, np.zeros((2, 2))],\n",
    "                 [np.zeros((2, 2)), np.zeros((2, 2)), inva]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621ee877",
   "metadata": {
    "id": "621ee877"
   },
   "outputs": [],
   "source": [
    "# Compute S and Z\n",
    "Y = np.matmul(invA, X)\n",
    "nu0 = np.matmul(invA, mu0)\n",
    "nuplus = np.matmul(invA, muplus)\n",
    "numinus = np.matmul(invA, muminus)\n",
    "U, S, Vh = np.linalg.svd(np.stack([nuplus, nu0, numinus]).T, full_matrices = False)\n",
    "Z = np.matmul(np.conj(U.T), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144fbeec",
   "metadata": {
    "id": "144fbeec",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute posterior and determine bound\n",
    "\n",
    "## Compute Limits\n",
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "warnings.resetwarnings();\n",
    "warnings.simplefilter('always');\n",
    "\n",
    "# Compute posterior and determine bound\n",
    "bound = []\n",
    "print(\"Calculating Bounds\")\n",
    "try:\n",
    "    for n in range(fq - fp):\n",
    "        mR = 2 * np.pi * (fp + n) / N / dT * R\n",
    "        Sn = S * mR / (2 - (mR) ** 2) # re-introduce frequency factor\n",
    "        Zn = Z[:, n]\n",
    "        pdf = lambda eps: np.sqrt(np.sum(4 * eps ** 2 * Sn ** 4 / (3 + eps ** 2 * Sn ** 2) ** 2)) * np.prod(np.exp(- 3 * np.abs(Zn) ** 2 / (3 + eps ** 2 * Sn ** 2)) / (3 + eps ** 2 * Sn ** 2))\n",
    "        upper = 10 / min(Sn)\n",
    "        norm = integrate.quad(pdf, 0, upper)[0]\n",
    "        while integrate.quad(pdf, 0, 2 * upper)[0] > norm * 1.01:\n",
    "            print(n)\n",
    "            upper *= 2\n",
    "            norm = integrate.quad(pdf, 0, upper)[0]\n",
    "        normedpdf = lambda eps: pdf(eps) / norm\n",
    "        epp_guess = 1 / max(Sn)\n",
    "        limit = optimize.fsolve(lambda eps: integrate.quad(normedpdf, 0, eps)[0] - 0.95, epp_guess)[0]\n",
    "        bound.append(limit)\n",
    "        print(\"n = %2d, bound = %2.6f\" %(n,limit))\n",
    "except RuntimeWarning:\n",
    "    breakpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9236a532",
   "metadata": {
    "id": "9236a532"
   },
   "outputs": [],
   "source": [
    "fname='SNIPE23Scan2024_04_18'+str(lowFreq)+'.hdf5';\n",
    "hf = h5py.File(fname, 'w')\n",
    "hf['frange']=[0.1,5]\n",
    "hf['Z'] = Z;\n",
    "hf['bounds'] = bound\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
